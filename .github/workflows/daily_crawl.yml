name: Daily School Crawler

on:
  schedule:
    - cron: '0 22 * * *' # 每天台灣時間早上 6 點執行
  workflow_dispatch:      # 允許手動按按鈕測試

permissions:
  contents: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

    # 3. 安裝爬蟲需要的套件 (加入 Playwright 安裝指令)
      - name: Install dependencies
        run: |
        python -m pip install --upgrade pip
        # 安裝您的程式需要的庫
        pip install requests beautifulsoup4 pandas lxml playwright
        
        # ⚠️ 關鍵步驟：安裝 Playwright 瀏覽器核心
        playwright install chromium

    # 4. 依序執行三個程式
      - name: Run Crawlers and Merge
        run: |
          python ultimate_bot_builder_v40_printHere.py
          python static_crawler_v43_recursive.py
          python merge_data.py

      - name: Commit and Push
        run: |
          git config --global user.name "GitHub Action"
          git config --global user.email "action@github.com"
          git add nihs_knowledge_full.json
          git commit -m "Auto-update school data" || exit 0
          git push
