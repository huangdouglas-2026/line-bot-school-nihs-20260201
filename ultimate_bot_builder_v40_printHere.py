# ====================================================
# ğŸ§  çµ‚æ¥µå¤§è…¦å»ºæ§‹è€… V40 (Target Locked / printHere ç²¾ç¢ºé–å®šç‰ˆ)
# ç›®æ¨™ï¼š
# 1. æ ¹æ“šä½¿ç”¨è€…æä¾›çš„ HTMLï¼Œé–å®š id="printHere" æŠ“å–å…§æ–‡
# 2. é–å®š .htmldisplay class æå–ç´”æ–‡å­—
# 3. å®Œæ•´ä¿ç•™å…§æ–‡èˆ‡é™„ä»¶ï¼Œèˆ‡çœŸå¯¦ç¶²å€ä¸€ä½µå­˜æª”
# ====================================================
import asyncio
import json
import re
import os
from datetime import datetime
from playwright.async_api import async_playwright, expect

# ğŸ“‚ è¨­å®š
TARGET_URL = "https://www.nihs.tp.edu.tw/nss/s/main/index"
MAX_PAGES = 10      # æ¯å€‹è™•å®¤æŠ“ 5 é 
OUTPUT_FILENAME = "nihs_final_v40.json"

TARGET_TABS = [
    "é‡è¦è¨Šæ¯ é ç±¤",
    "å­¸å‹™è™• é ç±¤",
    "æ•™å‹™è™• é ç±¤",
    "å¯¦ç¿’è™• é ç±¤",
    "è¼”å°å®¤ é ç±¤",
    "åœ–æ›¸é¤¨ é ç±¤",
    "æ”¿ä»¤å®£å° é ç±¤",
    "åˆä½œç¤¾ é ç±¤",
    "å­¸ç”Ÿæ´»å‹• é ç±¤",
    "æ–°ç”Ÿå°ˆå€ é ç±¤",
    "å‡å­¸è³‡è¨Š é ç±¤",
    "è€ƒè©¦è³‡è¨Š é ç±¤",
    "æ•™å¸«ç ”ç¿’ é ç±¤",
    "æ”¿ä»¤å®£å° é ç±¤",
]

all_data = []

async def force_close_modal(page):
    """æš´åŠ›é—œé–‰è¦–çª—"""
    await page.keyboard.press("Escape")
    try:
        # å˜—è©¦é»æ“Šå³ä¸Šè§’é—œé–‰éˆ•
        close_btn = page.locator("button.close, button[data-dismiss='modal'], #closeCross").first
        if await close_btn.is_visible():
            await close_btn.click()
    except: pass
    
    # é»æ“ŠèƒŒæ™¯ (åº§æ¨™ 0,0)
    await page.mouse.click(0, 0)
    await page.wait_for_timeout(500)

async def extract_details(page):
    """
    æå–è³‡æ–™ (åŸºæ–¼ HTML id="printHere")
    """
    data = {"body": "", "attachments": [], "real_url": "ç„¡æ³•å–å¾—"}
    
    try:
        # ç­‰å¾…è¦–çª—è¼‰å…¥ (ä»¥ mailto æŒ‰éˆ•æˆ– printHere å‡ºç¾ç‚ºæº–)
        try:
            await page.wait_for_selector("#printHere, a[href^='mailto:']", state="visible", timeout=5000)
        except:
            return data # é€¾æ™‚è¿”å›ç©ºè³‡æ–™

        # 1. æå– Permalink (é€™éƒ¨åˆ†ä¹‹å‰å·²é©—è­‰æˆåŠŸ)
        try:
            mailto = page.locator("a[href^='mailto:']").first
            if await mailto.count() > 0:
                href = await mailto.get_attribute("href")
                match = re.search(r'(https?://[^\s&]+)', href)
                if match: data["real_url"] = match.group(1).replace("&amp;", "&")
        except: pass
        
        # 2. æå–å…§æ–‡ (Body) - ã€æ ¸å¿ƒä¿®æ­£é»ã€‘
        # æ ¹æ“šæ‚¨çš„ HTMLï¼Œå…§å®¹åœ¨ #printHere ä¸‹é¢çš„ .htmldisplay
        # å¦‚æœæ²’æœ‰ .htmldisplayï¼Œå°±ç›´æ¥æŠ“ #printHere çš„æ–‡å­—
        print_here = page.locator("#printHere").first
        
        if await print_here.count() > 0:
            # å„ªå…ˆæ‰¾ .htmldisplay (é€šå¸¸åŒ…å«æ’ç‰ˆå¥½çš„å…§æ–‡)
            html_display = print_here.locator(".htmldisplay")
            if await html_display.count() > 0:
                data["body"] = await html_display.inner_text()
            else:
                # å‚™æ¡ˆï¼šç›´æ¥æŠ“ printHere å®¹å™¨æ–‡å­—
                data["body"] = await print_here.inner_text()
        else:
            # å‚™æ¡ˆï¼šå¦‚æœé€™ç¯‡å‰›å¥½æ²’æœ‰ printHere (èˆŠç‰ˆå…¬å‘Š)ï¼Œå›é€€åˆ°é€šç”¨é¸æ“‡å™¨
            fallback = page.locator(".modal-body, .module-detail").first
            if await fallback.count() > 0:
                data["body"] = await fallback.inner_text()

        # 3. æå–é™„ä»¶ (Attachments)
        # æƒæ #printHere å…§éƒ¨ä»¥åŠæ•´å€‹ modal
        modal_content = page.locator(".modal-content, div[role='dialog']").first
        
        # æ”¶é›†å€™é¸å€åŸŸ
        candidates = []
        if await print_here.count() > 0: candidates.append(print_here)
        if await modal_content.count() > 0: candidates.append(modal_content)
        
        seen_urls = set() # é˜²æ­¢é‡è¤‡
        
        for container in candidates:
            links = await container.locator("a").all()
            for link in links:
                href = await link.get_attribute("href")
                text = await link.inner_text()
                text = text.strip()
                
                if not href: continue
                href_lower = href.lower()
                
                # åˆ¤æ–·æ˜¯å¦ç‚ºæª”æ¡ˆ
                is_file = False
                # ç‰¹å¾µ A: åŒ…å« feeder
                if "feeder" in href_lower: is_file = True
                # ç‰¹å¾µ B: å‰¯æª”å
                elif any(ext in href_lower for ext in ['.pdf', '.doc', '.xls', '.ppt', '.zip', '.jpg', '.png']): is_file = True
                
                # æ’é™¤
                if "mailto:" in href_lower: is_file = False
                if not text: is_file = False 
                
                if is_file:
                    if href.startswith("/"): href = "https://www.nihs.tp.edu.tw" + href
                    
                    if href not in seen_urls:
                        data["attachments"].append({"name": text, "url": href})
                        seen_urls.add(href)

    except Exception as e:
        print(f"      âš ï¸ è§£æç´°ç¯€å¾®èª¤: {e}")
        
    return data

async def harvest_tab(page, tab_label):
    print(f"\nğŸ”µ æº–å‚™åˆ‡æ›è‡³: {tab_label} ...")
    
    # 1. é ç±¤åˆ‡æ›
    tab_link = page.locator(f"a[aria-label='{tab_label}']")
    tab_li = page.locator(f"//li[contains(@class, 'nav-item') and .//a[@aria-label='{tab_label}']]")
    
    if await tab_link.count() == 0:
        print(f"âŒ æ‰¾ä¸åˆ°é ç±¤: {tab_label}")
        return

    is_active = await tab_li.get_attribute("class")
    if "active" not in str(is_active):
        await tab_link.click()
        try:
            await expect(tab_li).to_have_class(re.compile(r"active"), timeout=5000)
            print("   âœ… é ç±¤åˆ‡æ›æˆåŠŸ")
        except:
            print("   âš ï¸ é ç±¤åˆ‡æ›è¶…æ™‚ï¼Œå˜—è©¦ç¹¼çºŒ...")
    else:
        print("   âœ… å·²ç¶“åœ¨ç›®æ¨™é ç±¤")

    container = tab_li
    try:
        await container.locator("table").wait_for(state="visible", timeout=5000)
    except: return

    # 2. åˆ†é è¿´åœˆ
    for current_page in range(1, MAX_PAGES + 1):
        print(f"   ğŸ“„ [ç¬¬ {current_page} é ] ...")

        # ç¿»é 
        if current_page > 1:
            page_btn = container.locator(f"button[title='ç¬¬{current_page}é ']")
            if await page_btn.count() == 0: page_btn = container.locator("button[title='ä¸‹ä¸€é ']")
            if await page_btn.count() > 0:
                try:
                    await page_btn.click()
                    await page.wait_for_timeout(3000)
                except: break
            else:
                print("      ğŸ ç„¡ä¸‹ä¸€é ")
                break

        # é€è¡Œè™•ç†
        rows = await container.locator("table tbody tr").all()
        total_rows = len(rows)
        print(f"      ğŸ“Š ç™¼ç¾ {total_rows} è¡Œ...")

        for i in range(total_rows):
            row = container.locator("table tbody tr").nth(i)
            if await row.locator("td").count() < 3: continue

            title_el = row.locator("td:nth-child(1) a").first
            if await title_el.count() == 0: continue

            title = await title_el.inner_text()
            unit = await row.locator("td:nth-child(2)").inner_text()
            date = await row.locator("td:nth-child(3)").inner_text()
            
            await title_el.scroll_into_view_if_needed()
            print(f"      [{i+1:02d}] {title[:10]}...", end="", flush=True)

            try:
                # é»æ“Šé–‹å•Ÿ
                await title_el.click()
                
                # æŠ“å–è©³ç´°è³‡æ–™
                details = await extract_details(page)
                
                # ç‹€æ…‹é¡¯ç¤º
                status = []
                if details["real_url"] != "ç„¡æ³•å–å¾—": status.append("ğŸ”—")
                if len(details["body"]) > 10: status.append(f"ğŸ“{len(details['body'])}å­—")
                if len(details["attachments"]) > 0: status.append(f"ğŸ“{len(details['attachments'])}")
                
                if status:
                    print(f" -> âœ… {' '.join(status)}", end="", flush=True)
                else:
                    print(f" -> âš ï¸ ç©ºè³‡æ–™", end="", flush=True)

                # å­˜æª”
                all_data.append({
                    "category": tab_label.replace(" é ç±¤", ""),
                    "date": date.strip(),
                    "unit": unit.strip(),
                    "title": title.strip(),
                    "url": details["real_url"],
                    "content": details["body"].strip(),
                    "attachments": details["attachments"],
                    "crawled_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })

            except Exception as e:
                print(f" -> âŒ {e}", end="", flush=True)

            # é—œé–‰è¦–çª—
            await force_close_modal(page)
            print(" -> â¹ï¸", flush=True)
            await page.wait_for_timeout(500)

async def main():
    print("ğŸš€ V40 (printHere ç²¾ç¢ºé–å®šç‰ˆ) å•Ÿå‹•...")
    async with async_playwright() as p:
        # æ”¹æˆ Trueï¼Œä»£è¡¨åœ¨èƒŒæ™¯åŸ·è¡Œ (ç„¡é ­æ¨¡å¼)
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()
        
        await page.goto(TARGET_URL)
        await page.wait_for_load_state("networkidle")
        
        for tab in TARGET_TABS:
            await harvest_tab(page, tab)
            await page.wait_for_timeout(1000)
        
        await browser.close()

    print("\n" + "="*30)
    if all_data:
        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=4)
        print(f"âœ… å…¨éƒ¨å®Œæˆï¼å…± {len(all_data)} ç­†ã€‚")
        print(f"ğŸ‘‰ æª”æ¡ˆ: {os.path.abspath(OUTPUT_FILENAME)}")
    else:
        print("âš ï¸ ç„¡è³‡æ–™")

if __name__ == "__main__":

    asyncio.run(main())
