import os
# âš¡ é–å®šå–®åŸ·è¡Œç·’
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

import json
import numpy as np
import google.generativeai as genai
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from datetime import datetime

# ==========================================
# ğŸ”‘ è¨­å®šå€
# ==========================================
MODEL_NAME = 'gemini-2.0-flash'
EMBED_MODEL = 'models/text-embedding-004'

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

app = Flask(__name__)

# ==========================================
# ğŸ§  æ··åˆå¼å¤§è…¦ (è¦å‰‡ç›´é€šè»Š + å‘é‡æª¢ç´¢)
# ==========================================
class HybridBrain:
    def __init__(self):
        self.ready = False
        
        # 1. çµæ§‹åŒ–è³‡æ–™ (çµ¦è¦å‰‡ç”¨)
        self.faq_data = {} 
        
        # 2. å‘é‡åŒ–è³‡æ–™ (çµ¦ AI ç”¨)
        self.vectors = None
        self.source_data = []
        
        self.load_data()

    def load_data(self):
        files = ['nihs_knowledge_full.json', 'nihs_faq.json', 'nihs_calendar.json']
        all_items = []
        
        try:
            for file in files:
                if os.path.exists(file):
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                        # A. è™•ç† FAQ (åŒæ™‚å­˜å…¥è¦å‰‡åº«èˆ‡å‘é‡åº«)
                        if file == 'nihs_faq.json':
                            self.faq_data = data # å­˜ä¸‹ä¾†åšç›´é€šè»Š
                            
                            # ä¹Ÿè¦æ”¾é€²å‘é‡åº«ï¼Œä»¥é˜²è¬ä¸€
                            traffic = data.get('traffic', {})
                            all_items.append(f"ã€äº¤é€šã€‘åœ°å€:{traffic.get('address')} æ·é‹:{traffic.get('mrt')} å…¬è»Š:{traffic.get('bus')}")
                            for c in data.get('contacts', []):
                                all_items.append(f"ã€é›»è©±ã€‘{c.get('title')}: {c.get('phone')}")

                        # B. è™•ç†è¡Œäº‹æ›†
                        elif isinstance(data, list):
                            for item in data:
                                if 'event' in item:
                                    all_items.append(f"ã€è¡Œäº‹æ›†ã€‘æ—¥æœŸ:{item.get('date')} æ´»å‹•:{item.get('event')}")
                                else: # å…¬å‘Š
                                    # æ“·å–è¼ƒé•·å…§å®¹ä»¥å¢åŠ æº–åº¦
                                    content = str(item.get('content', ''))[:300]
                                    all_items.append(f"ã€å…¬å‘Šã€‘æ¨™é¡Œ:{item.get('title')} å…§å®¹:{content}")

            # å‘é‡åŒ–è™•ç†
            print(f"ğŸ“¡ æ­£åœ¨å»ºç«‹å‘é‡ç´¢å¼• (å…± {len(all_items)} ç­†)...")
            batch_size = 50
            combined_embeddings = []
            
            for i in range(0, len(all_items), batch_size):
                batch = all_items[i : i + batch_size]
                try:
                    res = genai.embed_content(model=EMBED_MODEL, content=batch, task_type="retrieval_document")
                    combined_embeddings.extend(res['embedding'])
                except:
                    # é¿å…å–®ä¸€æ‰¹æ¬¡å¤±æ•—å°è‡´å…¨æ›
                    combined_embeddings.extend([[0]*768] * len(batch))
                    
            self.vectors = np.array(combined_embeddings).astype('float32')
            self.source_data = all_items
            self.ready = True
            print("âœ… æ··åˆå¤§è…¦å•Ÿå‹•å®Œç•¢ï¼")

        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}")

    # ğŸ”¥ é—œéµï¼šè¦å‰‡ç›´é€šè»Š (Rule-Based Router)
    def check_rules(self, query):
        q = query.lower()
        
        # 1. æ””æˆªã€Œäº¤é€šã€ç›¸é—œ
        if any(k in q for k in ['äº¤é€š', 'åœ°å€', 'åœ¨å“ª', 'æ·é‹', 'å…¬è»Š', 'æ€éº¼å»']):
            t = self.faq_data.get('traffic', {})
            return (
                "ğŸ« **å…§æ¹–é«˜å·¥äº¤é€šè³‡è¨Š**\n\n"
                f"ğŸ“ **åœ°å€**ï¼š{t.get('address', 'ç„¡è³‡æ–™')}\n"
                f"ğŸš‡ **æ·é‹**ï¼š{t.get('mrt', 'ç„¡è³‡æ–™')}\n"
                f"ğŸšŒ **å…¬è»Š**ï¼š\n{t.get('bus', 'ç„¡è³‡æ–™')}"
            )
            
        # 2. æ””æˆªã€Œé›»è©±ã€ç›¸é—œ
        if any(k in q for k in ['é›»è©±', 'åˆ†æ©Ÿ', 'è¯çµ¡', 'ç¸½æ©Ÿ', 'æ ¡å®‰']):
            contacts = self.faq_data.get('contacts', [])
            msg = "ğŸ“ **å…§æ¹–é«˜å·¥å¸¸ç”¨é›»è©±**\n"
            for c in contacts:
                msg += f"\nğŸ”¸ {c.get('title')}: {c.get('phone')}"
            return msg
            
        return None

    def search_vector(self, query, top_k=5):
        if not self.ready or self.vectors is None: return []
        try:
            res = genai.embed_content(model=EMBED_MODEL, content=query, task_type="retrieval_query")
            q_vec = np.array(res['embedding']).astype('float32')
            
            sims = np.dot(self.vectors, q_vec) / (
                np.linalg.norm(self.vectors, axis=1) * np.linalg.norm(q_vec) + 1e-10
            )
            top_indices = np.argsort(sims)[-top_k:][::-1]
            return [self.source_data[i] for i in top_indices]
        except: return []

    def ask(self, user_query):
        # âš¡ ç¬¬ä¸€é—œï¼šå…ˆæŸ¥è¦å‰‡ç›´é€šè»Š
        direct_answer = self.check_rules(user_query)
        if direct_answer:
            return direct_answer

        # âš¡ ç¬¬äºŒé—œï¼šAI å‘é‡æª¢ç´¢ (è™•ç†è¡Œäº‹æ›†ã€å…¬å‘Š)
        if not self.ready: return "ç³»çµ±ç†±æ©Ÿä¸­..."
        
        relevant_docs = self.search_vector(user_query, top_k=5)
        
        # è‹¥æ˜¯å•è¡Œäº‹æ›†ï¼Œå¼·åˆ¶å¤šæŠ“å¹¾ç­†
        if "è¡Œäº‹æ›†" in user_query:
             relevant_docs = self.search_vector("2026å¹´è¡Œäº‹æ›†", top_k=10)

        context = "\n---\n".join(relevant_docs)
        now = datetime.now()
        
        prompt = f"""
ä½ æ˜¯ã€Œå…§æ¹–é«˜å·¥æ ¡åœ’å°å¹«æ‰‹ã€ã€‚ä»Šå¤©æ˜¯ {now.year}/{now.month}/{now.day}ã€‚
è«‹æ ¹æ“šã€åƒè€ƒè³‡æ–™ã€‘å›ç­”å•é¡Œã€‚

ã€ç­–ç•¥ã€‘ï¼š
1. **è¡Œäº‹æ›†**ï¼šè«‹åˆ—å‡ºæœ€æ¥è¿‘ä»Šå¤©çš„æœªä¾†æ´»å‹•ã€‚
2. **å…¬å‘Š**ï¼šè«‹æ‘˜è¦é‡é»ã€‚
3. **æŸ¥ç„¡è³‡æ–™**ï¼šè‹¥è³‡æ–™å®Œå…¨ç„¡é—œï¼Œè«‹å›è¦†ã€ŒæŠ±æ­‰ï¼Œç›®å‰å…¬å‘Šä¸­æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€ã€‚

ã€åƒè€ƒè³‡æ–™ã€‘ï¼š
{context}

ã€å•é¡Œã€‘ï¼š{user_query}
"""
        try:
            model = genai.GenerativeModel(MODEL_NAME)
            response = model.generate_content(prompt, generation_config={"temperature": 0.3})
            return response.text
        except:
            return "å°å¹«æ‰‹é€£ç·šå¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

brain = HybridBrain()

@app.route("/", methods=['GET'])
def index(): return "Bot Live", 200

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except: abort(400)
    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    reply = brain.ask(event.message.text.strip())
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply))

if __name__ == "__main__":
    app.run(port=10000)
