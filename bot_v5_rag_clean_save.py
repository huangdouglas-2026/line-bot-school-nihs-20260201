import os
# âš¡ é–å®šå–®åŸ·è¡Œç·’ï¼Œé€™åœ¨ Render çš„å—é™ç’°å¢ƒä¸­èƒ½æä¾›æœ€é«˜ç©©å®šæ€§
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

import json
import numpy as np
import google.generativeai as genai
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from datetime import datetime

# ==========================================
# ğŸ”‘ è¨­å®šå€
# ==========================================
MODEL_NAME = 'gemini-2.0-flash'
EMBED_MODEL = 'models/text-embedding-004' # Google é›²ç«¯å‘é‡æ¨¡å‹

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

app = Flask(__name__)

# ==========================================
# ğŸ§  è¼•é‡åŒ–å¤§è…¦ (API å‘é‡æª¢ç´¢ç‰ˆ)
# ==========================================
class LightVectorBrain:
    def __init__(self):
        self.ready = False
        self.source_data = []
        self.vectors = None
        self.load_and_vectorize()

    def load_and_vectorize(self):
        """ è®€å–è³‡æ–™ä¸¦ã€åˆ†æ‰¹ã€é€é API å–å¾—å‘é‡ """
        files = ['nihs_knowledge_full.json', 'nihs_faq.json', 'nihs_calendar.json']
        all_items = []
        
        try:
            for file in files:
                if os.path.exists(file):
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if file == 'nihs_faq.json':
                            # FAQ è™•ç†
                            all_items.append(f"ã€åœ°å€äº¤é€šã€‘{data['traffic']['address']} {data['traffic']['mrt']}")
                            for c in data.get('contacts', []):
                                all_items.append(f"ã€è¯çµ¡é›»è©±ã€‘{c.get('title')}: {c.get('phone')}")
                        elif isinstance(data, list):
                            for item in data:
                                if 'event' in item: # è¡Œäº‹æ›†
                                    all_items.append(f"ã€è¡Œäº‹æ›†ã€‘æ—¥æœŸ:{item.get('date')} æ´»å‹•:{item.get('event')}")
                                else: # å…¬å‘Š
                                    # è£œä¸Šå–®ä½è³‡è¨Šï¼Œå¢åŠ è¾¨è­˜åº¦
                                    unit = item.get('unit', '')
                                    all_items.append(f"ã€å…¬å‘Šã€‘å–®ä½:{unit} æ¨™é¡Œ:{item.get('title')} å…§å®¹:{str(item.get('content'))[:200]}")
            
            if not all_items: return

            print(f"ğŸ“¡ æº–å‚™å‘é‡åŒ– {len(all_items)} ç­†è³‡æ–™...")
            batch_size = 50  # æ¯æ‰¹ 50 ç­†ï¼Œç¬¦åˆå…è²»ç‰ˆé™åˆ¶
            combined_embeddings = []

            for i in range(0, len(all_items), batch_size):
                batch = all_items[i : i + batch_size]
                # å‘¼å« Google API
                result = genai.embed_content(
                    model=EMBED_MODEL,
                    content=batch,
                    task_type="retrieval_document"
                )
                combined_embeddings.extend(result['embedding'])
                print(f"â³ é€²åº¦: {min(i + batch_size, len(all_items))}/{len(all_items)}")

            self.vectors = np.array(combined_embeddings).astype('float32')
            self.source_data = all_items
            self.ready = True
            print("âœ… é›²ç«¯å‘é‡å¤§è…¦å•Ÿå‹•æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ å‘é‡åŒ–å¤±æ•—: {e}")

    def search(self, query, top_k=5):
        """ è¨ˆç®—ç›¸ä¼¼åº¦æ‰¾å‡ºæœ€ç›¸é—œçš„è³‡æ–™ (æ“´å¤§è‡³ 5 ç­†) """
        if not self.ready: return []
        
        try:
            # 1. å–å¾—å•é¡Œå‘é‡
            res = genai.embed_content(model=EMBED_MODEL, content=query, task_type="retrieval_query")
            query_vec = np.array(res['embedding']).astype('float32')
            
            # 2. é¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—
            similarities = np.dot(self.vectors, query_vec) / (
                np.linalg.norm(self.vectors, axis=1) * np.linalg.norm(query_vec) + 1e-10
            )
            
            # 3. å–å¾—å‰ k åç´¢å¼•
            top_indices = np.argsort(similarities)[-top_k:][::-1]
            
            # é™¤éŒ¯ Log
            results = [self.source_data[i] for i in top_indices]
            print(f"ğŸ” ç”¨æˆ¶å•: {query}")
            print(f"ğŸ“– AI æŠ“åˆ°çš„å‰ {top_k} ç­†è³‡æ–™é–‹é ­: {[r[:30] for r in results]}")
            
            return results
        except Exception as e:
            print(f"âŒ æœå°‹éŒ¯èª¤: {e}")
            return []

    def ask(self, user_query):
        if not self.ready: return "æ ¡åœ’åŠ©æ‰‹æ­£åœ¨æ•´ç†è³‡æ–™ä¸­ï¼Œè«‹ç¨å€™..."

        # âš¡ æª¢ç´¢æ“´å¤§ç‚º 5 ç­†
        relevant_docs = self.search(user_query, top_k=5)
        
        # å¦‚æœçœŸçš„å®Œå…¨æ²’è³‡æ–™
        if not relevant_docs:
             return "æ‚¨çš„å•é¡Œå¾ˆå¥½ï¼ç›®å‰å…¬å‘Šä¸­æš«æ™‚æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚å»ºè­°æ‚¨è¯ç¹«å­¸æ ¡ï¼Œæˆ‘å€‘æœƒè¨˜éŒ„ä¸¦æ›´æ–°ã€‚"

        context = "\n---\n".join(relevant_docs)
        now = datetime.now()

        # âš¡ æ”¾å¯¬å¾Œçš„ Prompt
        prompt = f"""
ä½ æ˜¯ã€Œå…§æ¹–é«˜å·¥æ ¡åœ’å°å¹«æ‰‹ã€ã€‚ä»Šå¤©æ˜¯è¥¿å…ƒ {now.year}å¹´{now.month}æœˆ{now.day}æ—¥ã€‚
è«‹æ ¹æ“šä¸‹æ–¹ã€åƒè€ƒè³‡æ–™ã€‘å›ç­”å®¶é•·å•é¡Œã€‚

ã€å›ç­”ç­–ç•¥ã€‘ï¼š
1. **æœ‰å¹¾åˆ†è­‰æ“šèªªå¹¾åˆ†è©±**ï¼šåªè¦åƒè€ƒè³‡æ–™ä¸­æœ‰æåˆ°ç›¸é—œé—œéµå­—ï¼Œè«‹æ•´ç†å‡ºä¾†ã€‚
2. **æ‰¾ä¸åˆ°æ™‚**ï¼šè‹¥è³‡æ–™å…§å®¹å®Œå…¨ä¸ç›¸é—œï¼Œæ‰å›è¦†æŸ¥ç„¡è³‡æ–™çš„å®¢å¥—è©±ã€‚
3. **æ ¼å¼**ï¼šè«‹ç”¨è¦ªåˆ‡å£å»ï¼Œé‡é»æ¢åˆ—ï¼Œé©åº¦ä½¿ç”¨ Emojiã€‚
4. **æ—¥æœŸ**ï¼šå°‡æ°‘åœ‹å¹´ä»½è½‰ç‚ºè¥¿å…ƒã€‚

ã€åƒè€ƒè³‡æ–™ã€‘ï¼š
{context}

ã€å®¶é•·å•é¡Œã€‘ï¼š{user_query}
"""
        try:
            model = genai.GenerativeModel(MODEL_NAME)
            # æº«åº¦èª¿é«˜è‡³ 0.3ï¼Œå¢åŠ éˆæ´»æ€§
            response = model.generate_content(prompt, generation_config={"temperature": 0.3})
            return response.text
        except:
            return "å°å¹«æ‰‹é€£ç·šå¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

# å¯¦ä¾‹åŒ–
brain = LightVectorBrain()

# ==========================================
# ğŸŒ è·¯ç”±å€
# ==========================================
@app.route("/", methods=['GET'])
def index(): return "Bot Live", 200

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_msg = event.message.text.strip()
    reply = brain.ask(user_msg)
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply))

if __name__ == "__main__":
    app.run(port=10000)
