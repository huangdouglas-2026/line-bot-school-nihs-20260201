import os
import json
import numpy as np
import faiss
import google.generativeai as genai
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from datetime import datetime
from sentence_transformers import SentenceTransformer

# ==========================================
# ğŸ”‘ è¨­å®šå€
# ==========================================
MODEL_NAME = 'gemini-2.0-flash'
EMBED_MODEL_NAME = 'paraphrase-multilingual-MiniLM-L12-v2' # è¼•é‡ä¸”æ”¯æ´ä¸­æ–‡

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")

genai.configure(api_key=GEMINI_API_KEY)
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

app = Flask(__name__)

# ==========================================
# ğŸ§  å‘é‡å¤§è…¦ (FAISS ç‰ˆ)
# ==========================================
class VectorBrain:
    def __init__(self):
        self.ready = False
        self.encoder = SentenceTransformer(EMBED_MODEL_NAME) # è¼‰å…¥è¼•é‡åŒ–æ¨¡å‹
        self.source_data = [] # å­˜æ”¾åŸå§‹æ–‡å­—
        self.index = None
        self.load_and_build_index()

    def load_and_build_index(self):
        """ è®€å– JSON ä¸¦å»ºç«‹ FAISS å‘é‡ç´¢å¼• """
        files = ['nihs_knowledge_full.json', 'nihs_faq.json', 'nihs_calendar.json']
        all_items = []
        
        for file in files:
            if os.path.exists(file):
                with open(file, 'r', encoding='utf-8') as f:
                    content = json.load(f)
                    if isinstance(content, list):
                        all_items.extend([json.dumps(i, ensure_ascii=False) for i in content])
                    else:
                        all_items.append(json.dumps(content, ensure_ascii=False))

        if not all_items: return

        # 1. å°‡æ–‡å­—è½‰ç‚ºå‘é‡ (Embedding)
        self.source_data = all_items
        embeddings = self.encoder.encode(all_items)
        
        # 2. å»ºç«‹ FAISS ç´¢å¼•
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(np.array(embeddings).astype('float32'))
        
        self.ready = True
        print(f"âœ… FAISS ç´¢å¼•å»ºç«‹å®Œæˆï¼Œå…± {len(all_items)} ç­†è³‡æ–™")

    def search(self, query, top_k=4):
        """ å‘é‡æœå°‹ï¼šæ‰¾å‡ºæœ€ç›¸é—œçš„è³‡æ–™ """
        if not self.ready: return []
        query_vector = self.encoder.encode([query]).astype('float32')
        distances, indices = self.index.search(query_vector, top_k)
        
        # å›å‚³æœ€ç›¸é—œçš„åŸå§‹è³‡æ–™
        return [self.source_data[i] for i in indices[0] if i != -1]

    def ask(self, user_query):
        now = datetime.now()
        
        # âš¡ é—œéµå„ªåŒ–ï¼šåªæŠ“å–è·Ÿå•é¡Œæœ€ç›¸é—œçš„ 4 ç­†è³‡æ–™
        relevant_docs = self.search(user_query, top_k=4)
        context = "\n---\n".join(relevant_docs)

        prompt = f"""
ä½ æ˜¯ã€Œå…§æ¹–é«˜å·¥æ ¡åœ’å°å¹«æ‰‹ã€ã€‚ä»Šå¤© {now.year}/{now.month}/{now.day}ã€‚
è«‹ã€Œåš´æ ¼æ ¹æ“šã€ä¸‹æ–¹çŸ¥è­˜åº«å›ç­”ã€‚è‹¥è³‡æ–™ä¸­å®Œå…¨æ²’æœ‰èˆ‡ "{user_query}" ç›¸é—œçš„é—œéµå…§å®¹ï¼Œè«‹å›è¦†æŸ¥ç„¡è³‡æ–™çš„ç¾å¼é¢¨æ ¼ç¯„æœ¬ã€‚

ã€è¦å‰‡ã€‘ï¼š
1. è¥¿å…ƒå¹´å‘ˆç¾ã€‚
2. åƒ…é¡¯ç¤ºç•¶æœˆè¡Œäº‹æ›†ï¼ˆé™¤éæŒ‡å®šæœˆä»½ï¼‰ã€‚
3. åš´ç¦å¹»è¦ºï¼Œæ²’çœ‹åˆ°å°±èªªæ‰¾ä¸åˆ°ã€‚

ã€çŸ¥è­˜åº«ã€‘ï¼š
{context}

ã€å•é¡Œã€‘ï¼š{user_query}
"""
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(prompt, generation_config={"temperature": 0})
        return response.text

brain = VectorBrain()

# ==========================================
# ğŸŒ è·¯ç”±å€
# ==========================================
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except: abort(400)
    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    reply = brain.ask(event.message.text.strip())
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply))

if __name__ == "__main__":
    app.run(port=5000)
