import os
# âš¡ é–å®šå–®åŸ·è¡Œç·’ï¼Œé€™åœ¨ Render çš„å—é™ç’°å¢ƒä¸­èƒ½æä¾›æœ€é«˜ç©©å®šæ€§
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

import json
import numpy as np
import google.generativeai as genai
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from datetime import datetime

# ==========================================
# ğŸ”‘ è¨­å®šå€
# ==========================================
MODEL_NAME = 'gemini-2.0-flash'
EMBED_MODEL = 'models/text-embedding-004' # Google é›²ç«¯å‘é‡æ¨¡å‹

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

app = Flask(__name__)

# ==========================================
# ğŸ§  è¼•é‡åŒ–å¤§è…¦ (API å‘é‡æª¢ç´¢ç‰ˆ)
# ==========================================
class LightVectorBrain:
    def __init__(self):
        self.ready = False
        self.source_data = []
        self.vectors = None
        self.load_and_vectorize()

    def load_and_vectorize(self):
        """ è®€å–è³‡æ–™ä¸¦ã€åˆ†æ‰¹ã€é€é API å–å¾—å‘é‡ """
        files = ['nihs_knowledge_full.json', 'nihs_faq.json', 'nihs_calendar.json']
        all_items = []
        
        try:
            for file in files:
                if os.path.exists(file):
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if file == 'nihs_faq.json':
                            # FAQ è™•ç†
                            all_items.append(f"ã€åœ°å€äº¤é€šã€‘{data['traffic']['address']} {data['traffic']['mrt']}")
                            for c in data.get('contacts', []):
                                all_items.append(f"ã€è¯çµ¡é›»è©±ã€‘{c.get('title')}: {c.get('phone')}")
                        elif isinstance(data, list):
                            for item in data:
                                if 'event' in item: # è¡Œäº‹æ›†
                                    all_items.append(f"ã€è¡Œäº‹æ›†ã€‘æ—¥æœŸ:{item.get('date')} æ´»å‹•:{item.get('event')}")
                                else: # å…¬å‘Š
                                    all_items.append(f"ã€å…¬å‘Šã€‘æ¨™é¡Œ:{item.get('title')} å…§å®¹:{str(item.get('content'))[:200]}")
            
            if not all_items: return

            print(f"ğŸ“¡ æº–å‚™å‘é‡åŒ– {len(all_items)} ç­†è³‡æ–™...")
            batch_size = 50  # æ¯æ‰¹ 50 ç­†ï¼Œç¬¦åˆå…è²»ç‰ˆé™åˆ¶
            combined_embeddings = []

            for i in range(0, len(all_items), batch_size):
                batch = all_items[i : i + batch_size]
                result = genai.embed_content(
                    model=EMBED_MODEL,
                    content=batch,
                    task_type="retrieval_document"
                )
                combined_embeddings.extend(result['embedding'])
                print(f"â³ é€²åº¦: {min(i + batch_size, len(all_items))}/{len(all_items)}")

            self.vectors = np.array(combined_embeddings).astype('float32')
            self.source_data = all_items
            self.ready = True
            print("âœ… é›²ç«¯å‘é‡å¤§è…¦å•Ÿå‹•æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ å‘é‡åŒ–å¤±æ•—: {e}")

def search(self, query, top_k=5): # âš¡ ä¿®æ”¹é»ï¼šå¾ 3 æ”¹ç‚º 5ï¼Œæ“´å¤§æœå°‹ç¯„åœ
        if not self.ready: return []
        try:
            res = genai.embed_content(model=EMBED_MODEL, content=query, task_type="retrieval_query")
            query_vec = np.array(res['embedding']).astype('float32')
            
            similarities = np.dot(self.vectors, query_vec) / (
                np.linalg.norm(self.vectors, axis=1) * np.linalg.norm(query_vec) + 1e-10
            )
            
            top_indices = np.argsort(similarities)[-top_k:][::-1]
            
            # âš¡ ä¿®æ”¹é»ï¼šå°å‡ºå®ƒæ‰¾åˆ°çš„è³‡æ–™æ¨™é¡Œï¼Œæ–¹ä¾¿æˆ‘å€‘é™¤éŒ¯
            results = [self.source_data[i] for i in top_indices]
            print(f"ğŸ” ç”¨æˆ¶å•: {query}")
            print(f"ğŸ“– AI æŠ“åˆ°çš„å‰ {top_k} ç­†è³‡æ–™é–‹é ­: {[r[:50] for r in results]}")
            return results
        except Exception as e:
            print(f"âŒ æœå°‹å‡ºéŒ¯: {e}")
            return []

    def ask(self, user_query):
        if not self.ready: return "æ ¡åœ’åŠ©æ‰‹æ­£åœ¨æ•´ç†è³‡æ–™ä¸­ï¼Œè«‹ç¨å€™..."

        relevant_docs = self.search(user_query, top_k=5) # æ“´å¤§ç¯„åœ
        
        # å¦‚æœçœŸçš„å®Œå…¨æ²’æŠ“åˆ°è³‡æ–™
        if not relevant_docs:
            return "æ‚¨çš„å•é¡Œå¾ˆå¥½ï¼ç›®å‰å…¬å‘Šä¸­æš«æ™‚æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚å»ºè­°æ‚¨è¯ç¹«å­¸æ ¡ï¼Œæˆ‘å€‘æœƒè¨˜éŒ„ä¸¦æ›´æ–°ã€‚"

        context = "\n---\n".join(relevant_docs)
        now = datetime.now()

        # âš¡ ä¿®æ”¹é»ï¼šPrompt å¾®èª¿ï¼Œé¼“å‹µå®ƒå˜—è©¦å›ç­”ï¼Œä¸¦ç§»é™¤éåº¦åš´æ ¼çš„é™åˆ¶
        prompt = f"""
ä½ æ˜¯å…§æ¹–é«˜å·¥æ ¡åœ’å°å¹«æ‰‹ã€‚ä»Šå¤©æ˜¯ {now.year}/{now.month}/{now.day}ã€‚
è«‹æ ¹æ“šä¸‹æ–¹ã€åƒè€ƒè³‡æ–™ã€‘å›ç­”å•é¡Œã€‚

ã€å›ç­”ç­–ç•¥ã€‘ï¼š
1. **æœ‰å¹¾åˆ†è­‰æ“šèªªå¹¾åˆ†è©±**ï¼šåªè¦åƒè€ƒè³‡æ–™ä¸­æœ‰æåˆ°ç›¸é—œé—œéµå­—æˆ–æ¨™é¡Œï¼Œè«‹å°‡è©²è³‡è¨Šæ•´ç†å‡ºä¾†çµ¦å®¶é•·ã€‚
2. **æ‰¾ä¸åˆ°æ™‚**ï¼šè‹¥è³‡æ–™å®Œå…¨ä¸ç›¸é—œï¼Œæ‰å›è¦†æŸ¥ç„¡è³‡æ–™çš„å®¢å¥—è©±ã€‚
3. **æ ¼å¼**ï¼šè«‹ç”¨è¦ªåˆ‡çš„å£å»ï¼Œé‡é»æ¢åˆ—ã€‚
4. **æ—¥æœŸ**ï¼šå°‡æ°‘åœ‹å¹´ä»½è½‰ç‚ºè¥¿å…ƒ (ä¾‹å¦‚ 114å¹´ -> 2025å¹´)ã€‚

ã€åƒè€ƒè³‡æ–™ã€‘ï¼š
{context}

ã€å®¶é•·å•é¡Œã€‘ï¼š{user_query}
"""
        try:
            model = genai.GenerativeModel(MODEL_NAME)
            # âš¡ ä¿®æ”¹é»ï¼šç¨å¾®æé«˜æº«åº¦ (0.1 -> 0.3)ï¼Œè®“å®ƒæ¯”è¼ƒéˆæ´»ä¸€é»
            response = model.generate_content(prompt, generation_config={"temperature": 0.3})
            return response.text
        except:
            return "å°å¹«æ‰‹é€£ç·šå¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
            

# å¯¦ä¾‹åŒ–
brain = LightVectorBrain()

# ==========================================
# ğŸŒ è·¯ç”±å€
# ==========================================
@app.route("/", methods=['GET'])
def index(): return "Bot Live", 200

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_msg = event.message.text.strip()
    reply = brain.ask(user_msg)
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply))

# ğŸ‘‡ æ–°å¢é€™å€‹è¨ºæ–·è·¯å¾‘
@app.route("/status", methods=['GET'])
def status():
    # æª¢æŸ¥å‘é‡è³‡æ–™åº«ç‹€æ…‹
    if not brain.ready:
        return "âš ï¸ è…¦è¢‹å°šæœªå°±ç·’ (Loading...)", 503
    
    count = len(brain.source_data)
    # é¡¯ç¤ºå‰ 5 ç­†è³‡æ–™æ¨™é¡Œï¼Œç¢ºèªå®ƒè®€åˆ°äº†ä»€éº¼
    preview = "\n".join([s[:50] + "..." for s in brain.source_data[:5]])
    
    return f"""
    <h1>ğŸ¤– æ©Ÿå™¨äººå¥åº·å ±å‘Š</h1>
    <p>âœ… ç‹€æ…‹: Online</p>
    <p>ğŸ“š çŸ¥è­˜åº«ç­†æ•¸: <strong>{count}</strong> ç­† (æ­£å¸¸æ‡‰ç´„ 1600 ç­†)</p>
    <hr>
    <h3>ğŸ” è³‡æ–™é è¦½ (å‰ 5 ç­†):</h3>
    <pre>{preview}</pre>
    """, 200

if __name__ == "__main__":
    app.run(port=10000)


