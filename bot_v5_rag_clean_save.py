import os
# âš¡ é–å®šå–®åŸ·è¡Œç·’
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

import json
import numpy as np
import google.generativeai as genai
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from datetime import datetime

# ==========================================
# ğŸ”‘ è¨­å®šå€
# ==========================================
MODEL_NAME = 'gemini-2.0-flash'
EMBED_MODEL = 'models/text-embedding-004'

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

app = Flask(__name__)

# ==========================================
# ğŸ§  é›™å±¤å‘é‡å¤§è…¦ (Split-Index Brain)
# ==========================================
class DualVectorBrain:
    def __init__(self):
        self.ready = False
        # å»ºç«‹å…©å€‹ç¨ç«‹çš„è³‡æ–™åº«
        self.core_data = []      # å­˜æ”¾ FAQã€è¡Œäº‹æ›† (é«˜æ¬Šé‡)
        self.core_vectors = None
        
        self.news_data = []      # å­˜æ”¾å…¬å‘Š (ä½æ¬Šé‡)
        self.news_vectors = None
        
        self.load_and_vectorize()

    def embed_batch(self, text_list):
        """ æ‰¹æ¬¡å‘é‡åŒ–å·¥å…· """
        if not text_list: return None
        batch_size = 50
        all_vecs = []
        print(f"ğŸ“¡ æ­£åœ¨è™•ç† {len(text_list)} ç­†è³‡æ–™...")
        
        for i in range(0, len(text_list), batch_size):
            batch = text_list[i : i + batch_size]
            try:
                res = genai.embed_content(model=EMBED_MODEL, content=batch, task_type="retrieval_document")
                all_vecs.extend(res['embedding'])
            except Exception as e:
                print(f"âš ï¸ Batch error: {e}")
                # è£œç©ºå‘é‡é˜²å´©æ½°
                all_vecs.extend([[0]*768] * len(batch))
                
        return np.array(all_vecs).astype('float32')

    def load_and_vectorize(self):
        files = ['nihs_knowledge_full.json', 'nihs_faq.json', 'nihs_calendar.json']
        
        core_items = [] # æ ¸å¿ƒå€
        news_items = [] # å…¬å‘Šå€

        try:
            for file in files:
                if os.path.exists(file):
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                        # 1. è™•ç† FAQ (æ”¾å…¥æ ¸å¿ƒå€)
                        if file == 'nihs_faq.json':
                            traffic = data.get('traffic', {})
                            # å¼·åŠ›é—œéµå­—æ¤å…¥
                            core_items.append(
                                f"ã€å­¸æ ¡äº¤é€šè³‡è¨Šã€‘(é—œéµå­—: æ€éº¼å», åœ°å€, æ·é‹, å…¬è»Š)\n"
                                f"åœ°å€: {traffic.get('address')}\n"
                                f"æ·é‹: {traffic.get('mrt')}\n"
                                f"å…¬è»Š: {traffic.get('bus')}"
                            )
                            for c in data.get('contacts', []):
                                core_items.append(f"ã€è¯çµ¡é›»è©±ã€‘{c.get('title')} é›»è©±:{c.get('phone')} (é—œéµå­—: åˆ†æ©Ÿ, æ‰¾è€å¸«)")
                        
                        # 2. è™•ç†è¡Œäº‹æ›† (æ”¾å…¥æ ¸å¿ƒå€)
                        elif file == 'nihs_calendar.json':
                            for item in data:
                                core_items.append(f"ã€è¡Œäº‹æ›†ã€‘æ—¥æœŸ:{item.get('date')} æ´»å‹•:{item.get('event')}")
                        
                        # 3. è™•ç†å…¬å‘Š (æ”¾å…¥å…¬å‘Šå€)
                        elif file == 'nihs_knowledge_full.json':
                            for item in data:
                                unit = item.get('unit', '')
                                content = str(item.get('content', ''))[:200]
                                news_items.append(f"ã€å…¬å‘Šã€‘å–®ä½:{unit} æ¨™é¡Œ:{item.get('title')} å…§å®¹:{content}")

            # é–‹å§‹å‘é‡åŒ– (åˆ†é–‹è™•ç†)
            print("ğŸš€ æ­£åœ¨å»ºç«‹æ ¸å¿ƒè³‡æ–™åº« (Core Index)...")
            self.core_vectors = self.embed_batch(core_items)
            self.core_data = core_items

            print("ğŸš€ æ­£åœ¨å»ºç«‹å…¬å‘Šè³‡æ–™åº« (News Index)...")
            self.news_vectors = self.embed_batch(news_items)
            self.news_data = news_items
            
            self.ready = True
            print(f"âœ… é›™å±¤å¤§è…¦å•Ÿå‹•å®Œç•¢ï¼æ ¸å¿ƒ:{len(core_items)}ç­†, å…¬å‘Š:{len(news_items)}ç­†")

        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}")

    def search_layer(self, query_vec, vectors, data, top_k=3):
        """ é€šç”¨æœå°‹å‡½å¼ """
        if vectors is None or len(data) == 0: return [], []
        
        # è¨ˆç®—ç›¸ä¼¼åº¦
        sims = np.dot(vectors, query_vec) / (
            np.linalg.norm(vectors, axis=1) * np.linalg.norm(query_vec) + 1e-10
        )
        top_indices = np.argsort(sims)[-top_k:][::-1]
        
        results = [data[i] for i in top_indices]
        scores = [sims[i] for i in top_indices]
        return results, scores

    def ask(self, user_query):
        if not self.ready: return "ç³»çµ±ç†±æ©Ÿä¸­ï¼Œè«‹ç¨å€™..."

        try:
            # 1. å–å¾—å•é¡Œå‘é‡
            res = genai.embed_content(model=EMBED_MODEL, content=user_query, task_type="retrieval_query")
            q_vec = np.array(res['embedding']).astype('float32')

            final_docs = []
            
            # ğŸ” ç¬¬ä¸€å±¤ï¼šæœæ ¸å¿ƒå€ (FAQ/è¡Œäº‹æ›†)
            core_docs, core_scores = self.search_layer(q_vec, self.core_vectors, self.core_data, top_k=3)
            
            # åˆ¤æ–·æ ¸å¿ƒå€æ˜¯å¦æœ‰å¼·é—œè¯ (é–€æª»å€¼ 0.55)
            if core_docs and core_scores[0] > 0.55:
                print(f"ğŸ¯ å‘½ä¸­æ ¸å¿ƒè³‡æ–™! åˆ†æ•¸: {core_scores[0]}")
                final_docs = core_docs
            else:
                # ğŸ” ç¬¬äºŒå±¤ï¼šæœå…¬å‘Šå€ (å¦‚æœæ ¸å¿ƒå€æ²’æ‰¾åˆ°å¥½çš„)
                print("ğŸ”„ æ ¸å¿ƒå€ç„¡æ˜é¡¯é—œè¯ï¼Œè½‰æœå…¬å‘Šå€...")
                news_docs, news_scores = self.search_layer(q_vec, self.news_vectors, self.news_data, top_k=5)
                final_docs = news_docs

            if not final_docs:
                return "æ‚¨çš„å•é¡Œå¾ˆå¥½ï¼ç›®å‰å…¬å‘Šä¸­æš«æ™‚æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚å»ºè­°æ‚¨è¯ç¹«å­¸æ ¡ï¼Œæˆ‘å€‘æœƒè¨˜éŒ„ä¸¦æ›´æ–°ã€‚"

            context = "\n---\n".join(final_docs)
            now = datetime.now()

            prompt = f"""
ä½ æ˜¯ã€Œå…§æ¹–é«˜å·¥æ ¡åœ’å°å¹«æ‰‹ã€ã€‚ä»Šå¤©æ˜¯è¥¿å…ƒ {now.year}/{now.month}/{now.day}ã€‚
è«‹æ ¹æ“šã€åƒè€ƒè³‡æ–™ã€‘å›ç­”å•é¡Œã€‚

ã€å›ç­”ç­–ç•¥ã€‘ï¼š
1. **ç²¾æº–å„ªå…ˆ**ï¼šè‹¥è³‡æ–™ä¾†è‡ªã€å­¸æ ¡äº¤é€šè³‡è¨Šã€‘æˆ–ã€è¯çµ¡é›»è©±ã€‘ï¼Œè«‹ç›´æ¥çµ¦å‡ºç­”æ¡ˆï¼Œä¸éœ€è¦å»¢è©±ã€‚
2. **å…¬å‘Šæ•´ç†**ï¼šè‹¥è³‡æ–™ä¾†è‡ªã€å…¬å‘Šã€‘ï¼Œè«‹æ‘˜è¦é‡é»ã€‚
3. **æŸ¥ç„¡è³‡æ–™**ï¼šè‹¥è³‡æ–™èˆ‡å•é¡Œç„¡é—œï¼Œè«‹ç›´æ¥èªªæ‰¾ä¸åˆ°ã€‚

ã€åƒè€ƒè³‡æ–™ã€‘ï¼š
{context}

ã€å®¶é•·å•é¡Œã€‘ï¼š{user_query}
"""
            model = genai.GenerativeModel(MODEL_NAME)
            response = model.generate_content(prompt, generation_config={"temperature": 0.3})
            return response.text

        except Exception as e:
            print(f"âŒ å•ç­”éŒ¯èª¤: {e}")
            return "å°å¹«æ‰‹é€£ç·šå¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

brain = DualVectorBrain()

@app.route("/", methods=['GET'])
def index(): return "Bot Live", 200

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except: abort(400)
    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    reply = brain.ask(event.message.text.strip())
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply))

if __name__ == "__main__":
    app.run(port=10000)
