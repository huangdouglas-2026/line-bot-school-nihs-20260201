import os
# âš¡ é–å®šå–®åŸ·è¡Œç·’ï¼Œé€™åœ¨ Render çš„å—é™ç’°å¢ƒä¸­èƒ½æä¾›æœ€é«˜ç©©å®šæ€§
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

import json
import numpy as np
import google.generativeai as genai
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from datetime import datetime

# ==========================================
# ğŸ”‘ è¨­å®šå€
# ==========================================
MODEL_NAME = 'gemini-2.0-flash'
EMBED_MODEL = 'models/text-embedding-004' # Google é›²ç«¯å‘é‡æ¨¡å‹

GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.environ.get("LINE_CHANNEL_SECRET")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

app = Flask(__name__)

# ==========================================
# ğŸ§  è¼•é‡åŒ–å¤§è…¦ (API å‘é‡æª¢ç´¢ç‰ˆ)
# ==========================================
class LightVectorBrain:
    def __init__(self):
        self.ready = False
        self.source_data = []
        self.vectors = None
        self.load_and_vectorize()

    def load_and_vectorize(self):
        """ è®€å–è³‡æ–™ä¸¦ã€åˆ†æ‰¹ã€é€é API å–å¾—å‘é‡ """
        files = ['nihs_knowledge_full.json', 'nihs_faq.json', 'nihs_calendar.json']
        all_items = []
        
        try:
            for file in files:
                if os.path.exists(file):
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                        # âš¡ é‡å° FAQ é€²è¡Œã€Œé—œéµå­—åŠ å¼·ã€ï¼Œç¢ºä¿ä¸æœƒè¢«å…¬å‘Šæ·¹æ²’
                        if file == 'nihs_faq.json':
                            # è™•ç†äº¤é€šï¼šåŠ ä¸Šã€Œæ€éº¼å»ã€å…¬è»Šã€æ·é‹ã€ç­‰å¼·é—œéµå­—
                            traffic = data.get('traffic', {})
                            traffic_str = (
                                f"ã€å­¸æ ¡äº¤é€šè³‡è¨Šã€‘(é—œéµå­—: æ€éº¼å»å­¸æ ¡, åœ°å€, ä½ç½®, æ·é‹, å…¬è»Š)\n"
                                f"åœ°å€: {traffic.get('address', 'ç„¡')}\n"
                                f"æ·é‹: {traffic.get('mrt', 'ç„¡')}\n"
                                f"å…¬è»Š: {traffic.get('bus', 'ç„¡')}"
                            )
                            all_items.append(traffic_str)
                            
                            # è™•ç†é›»è©±ï¼šåŠ ä¸Šã€Œé›»è©±ã€åˆ†æ©Ÿã€è¯çµ¡ã€ç­‰å¼·é—œéµå­—
                            for c in data.get('contacts', []):
                                contact_str = f"ã€å­¸æ ¡è¯çµ¡é›»è©±ã€‘è™•å®¤:{c.get('title')} é›»è©±:{c.get('phone')} (é—œéµå­—: åˆ†æ©Ÿ, æ‰¾è€å¸«)"
                                all_items.append(contact_str)

                        elif isinstance(data, list):
                            for item in data:
                                if 'event' in item: # è¡Œäº‹æ›†
                                    all_items.append(f"ã€è¡Œäº‹æ›†ã€‘æ—¥æœŸ:{item.get('date')} æ´»å‹•:{item.get('event')}")
                                else: # å…¬å‘Š
                                    unit = item.get('unit', '')
                                    # é™åˆ¶å…¬å‘Šé•·åº¦ï¼Œé¿å…å¹²æ“¾ä¸»è¦è³‡è¨Š
                                    content = str(item.get('content', ''))[:200]
                                    all_items.append(f"ã€å…¬å‘Šã€‘å–®ä½:{unit} æ¨™é¡Œ:{item.get('title')} å…§å®¹:{content}")
            
            if not all_items: return

            print(f"ğŸ“¡ æº–å‚™å‘é‡åŒ– {len(all_items)} ç­†è³‡æ–™...")
            batch_size = 50 
            combined_embeddings = []

            for i in range(0, len(all_items), batch_size):
                batch = all_items[i : i + batch_size]
                result = genai.embed_content(
                    model=EMBED_MODEL,
                    content=batch,
                    task_type="retrieval_document"
                )
                combined_embeddings.extend(result['embedding'])
                print(f"â³ é€²åº¦: {min(i + batch_size, len(all_items))}/{len(all_items)}")

            self.vectors = np.array(combined_embeddings).astype('float32')
            self.source_data = all_items
            self.ready = True
            print("âœ… é›²ç«¯å‘é‡å¤§è…¦å•Ÿå‹•æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ å‘é‡åŒ–å¤±æ•—: {e}")

    def search(self, query, top_k=5):
        """ è¨ˆç®—ç›¸ä¼¼åº¦æ‰¾å‡ºæœ€ç›¸é—œçš„è³‡æ–™ """
        if not self.ready: return []
        
        try:
            res = genai.embed_content(model=EMBED_MODEL, content=query, task_type="retrieval_query")
            query_vec = np.array(res['embedding']).astype('float32')
            
            similarities = np.dot(self.vectors, query_vec) / (
                np.linalg.norm(self.vectors, axis=1) * np.linalg.norm(query_vec) + 1e-10
            )
            
            top_indices = np.argsort(similarities)[-top_k:][::-1]
            
            # é¡¯ç¤º AI æŠ“åˆ°äº†ä»€éº¼ï¼Œæ–¹ä¾¿é™¤éŒ¯
            results = [self.source_data[i] for i in top_indices]
            print(f"ğŸ” ç”¨æˆ¶å•: {query}")
            print(f"ğŸ“– AI æŠ“åˆ°çš„å‰ {top_k} ç­†æ¨™é¡Œ: {[r[:20] for r in results]}")
            
            return results
        except Exception as e:
            print(f"âŒ æœå°‹éŒ¯èª¤: {e}")
            return []

    def ask(self, user_query):
        if not self.ready: return "æ ¡åœ’åŠ©æ‰‹æ­£åœ¨æ•´ç†è³‡æ–™ä¸­ï¼Œè«‹ç¨å€™..."

        relevant_docs = self.search(user_query, top_k=5)
        
        if not relevant_docs:
             return "æ‚¨çš„å•é¡Œå¾ˆå¥½ï¼ç›®å‰å…¬å‘Šä¸­æš«æ™‚æ‰¾ä¸åˆ°ç›¸é—œè³‡è¨Šã€‚å»ºè­°æ‚¨è¯ç¹«å­¸æ ¡ï¼Œæˆ‘å€‘æœƒè¨˜éŒ„ä¸¦æ›´æ–°ã€‚"

        context = "\n---\n".join(relevant_docs)
        now = datetime.now()

        prompt = f"""
ä½ æ˜¯ã€Œå…§æ¹–é«˜å·¥æ ¡åœ’å°å¹«æ‰‹ã€ã€‚ä»Šå¤©æ˜¯è¥¿å…ƒ {now.year}å¹´{now.month}æœˆ{now.day}æ—¥ã€‚
è«‹æ ¹æ“šä¸‹æ–¹ã€åƒè€ƒè³‡æ–™ã€‘å›ç­”å•é¡Œã€‚

ã€å›ç­”ç­–ç•¥ã€‘ï¼š
1. **å„ªå…ˆé †åº**ï¼šè‹¥å•é¡Œæ˜¯é—œæ–¼ã€Œäº¤é€šã€ã€ã€Œé›»è©±ã€æˆ–ã€Œè¡Œäº‹æ›†ã€ï¼Œè«‹å„ªå…ˆä½¿ç”¨æ¨™è¨˜ç‚ºã€å­¸æ ¡äº¤é€šè³‡è¨Šã€‘æˆ–ã€å­¸æ ¡è¯çµ¡é›»è©±ã€‘çš„è³‡æ–™ã€‚
2. **èª å¯¦å›ç­”**ï¼šåªè¦è³‡æ–™ä¸­æœ‰ç›¸é—œé—œéµå­—ï¼Œè«‹æ•´ç†å‡ºä¾†ï¼Œä¸è¦å®³æ€•å›ç­”ã€‚
3. **æ ¼å¼**ï¼šè¦ªåˆ‡ã€æ¢åˆ—å¼ã€åŠ å¼·èªæ°£ã€‚
4. **æ—¥æœŸè½‰æ›**ï¼šæ°‘åœ‹è½‰è¥¿å…ƒã€‚

ã€åƒè€ƒè³‡æ–™ã€‘ï¼š
{context}

ã€å®¶é•·å•é¡Œã€‘ï¼š{user_query}
"""
        try:
            model = genai.GenerativeModel(MODEL_NAME)
            response = model.generate_content(prompt, generation_config={"temperature": 0.3})
            return response.text
        except:
            return "å°å¹«æ‰‹é€£ç·šå¿™ç¢Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

# å¯¦ä¾‹åŒ–
brain = LightVectorBrain()

# ==========================================
# ğŸŒ è·¯ç”±å€
# ==========================================
@app.route("/", methods=['GET'])
def index(): return "Bot Live", 200

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_msg = event.message.text.strip()
    reply = brain.ask(user_msg)
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply))

if __name__ == "__main__":
    app.run(port=10000)
